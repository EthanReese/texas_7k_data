{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating timeseries\n",
    "\n",
    "This notebook goes through the steps of taking the NREL time series data provided to us by Xinshuo and mapping that to the Texas7k dataset given to us by Texas A&M University."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# We are going to do some pre-processing to make sure all asset names have underscores instead of spaces\n",
    "wind_forecast_df = pd.read_csv(\"./NREL Stuff/wind_day_ahead_forecast_site_2018.csv\")\n",
    "wind_actual_df = pd.read_csv(\"./NREL Stuff/wind_actual_1h_site_2018.csv\")\n",
    "load_forecast_df = pd.read_csv(\"./NREL Stuff/load_day_ahead_forecast_zone_2018.csv\")\n",
    "load_actuals_df = pd.read_csv(\"./NREL Stuff/load_actual_1h_2018.csv\")\n",
    "sol_forecast_df = pd.read_csv(\"./NREL Stuff/solar_day_ahead_forecast_site_2018.csv\")\n",
    "sol_actual_df = pd.read_csv(\"./NREL Stuff/solar_actual_1h_site_2018.csv\")\n",
    "\n",
    "wind_mappings = pd.read_csv(\"./NREL Stuff/Texas7k_NREL_wind_map.csv\")\n",
    "\n",
    "\n",
    "wind_forecast_df.columns = wind_forecast_df.columns.str.replace(' ', '_')\n",
    "wind_actual_df.columns = wind_actual_df.columns.str.replace(' ', '_')\n",
    "load_forecast_df.columns = load_forecast_df.columns.str.replace(' ', '_')\n",
    "load_actuals_df.columns = load_actuals_df.columns.str.replace(' ', '_')\n",
    "sol_forecast_df.columns = sol_forecast_df.columns.str.replace(' ', '_')\n",
    "sol_actual_df.columns = sol_actual_df.columns.str.replace(' ', '_')\n",
    "\n",
    "wind_forecast_df.to_csv(\"./NREL Stuff/wind_day_ahead_forecast_site_2018.csv\")\n",
    "wind_actual_df.to_csv(\"./NREL Stuff/wind_actual_1h_site_2018.csv\")\n",
    "load_forecast_df.to_csv(\"./NREL Stuff/load_day_ahead_forecast_zone_2018.csv\")\n",
    "load_actuals_df.to_csv(\"./NREL Stuff/load_actual_1h_2018.csv\")\n",
    "sol_forecast_df.to_csv(\"./NREL Stuff/solar_day_ahead_forecast_site_2018.csv\")\n",
    "sol_actual_df.to_csv(\"./NREL Stuff/solar_actual_1h_site_2018.csv\")\n",
    "\n",
    "\n",
    "wind_mappings['NREL Wind Site'] = wind_mappings['NREL Wind Site'].str.replace(' ', '_')  # or .replace as above\n",
    "wind_mappings.to_csv(\"./NREL Stuff/Texas7k_NREL_wind_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Note: our methodology here relies on the bus numbers being unique for wind and solar assets. Bus numbers\\nare not unique generally, but they appear to be so for ERCOT w/r/t solar and wind generators. If this is not\\nthe case generally, we will have to be far more careful about how to map them. One way to get around it would be\\nto store a dictionary with the number of times a non-unique bus has been used, and then use that to index properly\\naround a subset of length > 1 - old versions of this document (prior to Aug 17 2021) implemented something similar\\nfor wind, so we can revert to that if we need to in the future'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the files we will need (excluding the timeseries file given to us by Xinshuo)\n",
    "bus = pd.read_csv(\"./TX_Data/SourceData/bus.csv\")\n",
    "branch = pd.read_csv(\"./TX_Data/SourceData/branch.csv\")\n",
    "gen = pd.read_csv(\"./TX_Data/SourceData/gen.csv\")\n",
    "wind_mappings = pd.read_csv(\"./NREL Stuff/Texas7k_NREL_wind_map.csv\")\n",
    "solar_mappings = pd.read_csv(\"./NREL Stuff/Texas7k_NREL_solar_map.csv\")\n",
    "\n",
    "# we will produce forecasts and actuals between the datetimes start_time_local and end_time_local\n",
    "start_time_local = \"2018-01-02 00:00:00\"\n",
    "end_time_local = \"2018-12-30 23:00:00\"\n",
    "# these tapering variables are used to trim the actuals to be consistent with the dates above\n",
    "actuals_taper_front = 30\n",
    "actuals_taper_back = -18\n",
    "\n",
    "forecasts_taper_front = 24 # need this for wind and load to equalize the length of the forecasts for each asset type\n",
    "\n",
    "'''Note: our methodology here relies on the bus numbers being unique for wind and solar assets. Bus numbers\n",
    "are not unique generally, but they appear to be so for ERCOT w/r/t solar and wind generators. If this is not\n",
    "the case generally, we will have to be far more careful about how to map them. One way to get around it would be\n",
    "to store a dictionary with the number of times a non-unique bus has been used, and then use that to index properly\n",
    "around a subset of length > 1 - old versions of this document (prior to Aug 17 2021) implemented something similar\n",
    "for wind, so we can revert to that if we need to in the future'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start with wind forecast for now.... can turn this into a function that applies to all the asset types later\n",
    "wind_forecast_df = pd.read_csv(\"./NREL Stuff/wind_day_ahead_forecast_site_2018.csv\")\n",
    "wind_actual_df = pd.read_csv(\"./NREL Stuff/wind_actual_1h_site_2018.csv\")\n",
    "\n",
    "# change this to just save out the whole year\n",
    "wind_forecasting_horizon = 24\n",
    "# we will get some days around the day that we are interested in to populate for this test run\n",
    "days_before = 1\n",
    "days_after = 1\n",
    "day_of_interest = 191 # july 10\n",
    "#wind_forecast_subset = wind_forecast_df.iloc[np.maximum(0,(day_of_interest-days_before - 1))*wind_forecasting_horizon:np.minimum(365,(day_of_interest+days_after))*wind_forecasting_horizon,:]\n",
    "#wind_actual_subset = wind_actual_df.iloc[np.maximum(0,(day_of_interest-days_before-1))*wind_forecasting_horizon:np.minimum(365,(day_of_interest+days_after))*wind_forecasting_horizon,:]\n",
    "# getting the year, month, day, and hour in order to mimic the RTS formatting\n",
    "#temp = wind_forecast_subset.loc[:,'Forecast_time']\n",
    "# dates = pd.to_datetime(temp).dt.tz_localize(\"UTC\") - datetime.timedelta(hours=6) #pull 6 hours for date consistency reasons\n",
    "# wind_forecast_subset.loc[:,'Forecast_time'] = pd.to_datetime(temp.loc[:,:]).\n",
    "\n",
    "wind_forecast_subset = wind_forecast_df.iloc[forecasts_taper_front:]\n",
    "wind_forecast_subset = wind_forecast_subset.reset_index()\n",
    "# has a few extra hours without Forecasts\n",
    "wind_actual_subset = wind_actual_df.iloc[actuals_taper_front:actuals_taper_back]\n",
    "# starting the actuals from the indicated date Jan 1 6 am\n",
    "# recall the times are in UTC, so this actually corresponds to Jan 1, 12 am local\n",
    "wind_actual_subset = wind_actual_subset.reset_index()\n",
    "# adjusted for full year -> cut out the hours that lacked forecasts on either end because I don't think it matters -ER\n",
    "dates = pd.Series(pd.date_range(start=start_time_local, end=end_time_local, freq='H'))\n",
    "# the above goes from Jan 1 12 am to Dec 30 11 pm to adjust for the fact that the time zones are in UTC but\n",
    "# Prescient operates in local time\n",
    "# this has the first 4 columns set up - what remains is to populate with the appropriate time series which correspond\n",
    "# to the correct assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Texas7k BusNum</th>\n",
       "      <th>Texas7k GenID</th>\n",
       "      <th>Texas7k SubNum</th>\n",
       "      <th>Texas7k Max MW</th>\n",
       "      <th>Texas7k Min MW</th>\n",
       "      <th>EIA-860 Plant Code</th>\n",
       "      <th>EIA-860 Plant Name</th>\n",
       "      <th>EIA-860 Operating Year</th>\n",
       "      <th>EIA-860 Nameplate Capacity (MW)</th>\n",
       "      <th>NREL Wind Site</th>\n",
       "      <th>Mapping Status</th>\n",
       "      <th>Distribution Factor</th>\n",
       "      <th>NREL Capacity Proportion</th>\n",
       "      <th>GEN UID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190193</td>\n",
       "      <td>1</td>\n",
       "      <td>3131</td>\n",
       "      <td>253.0</td>\n",
       "      <td>34.10</td>\n",
       "      <td>60902</td>\n",
       "      <td>Dermott Wind</td>\n",
       "      <td>2017</td>\n",
       "      <td>253.0</td>\n",
       "      <td>Amazon_Wind_Farm_Texas</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>60902_OnshoreWindTurbine_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120493</td>\n",
       "      <td>1</td>\n",
       "      <td>1261</td>\n",
       "      <td>99.8</td>\n",
       "      <td>20.75</td>\n",
       "      <td>58000</td>\n",
       "      <td>Anacacho Wind Farm  LLC</td>\n",
       "      <td>2012</td>\n",
       "      <td>99.8</td>\n",
       "      <td>Anacacho_Wind_Farm</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>58000_OnshoreWindTurbine_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>160281</td>\n",
       "      <td>1</td>\n",
       "      <td>2424</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.66</td>\n",
       "      <td>57927</td>\n",
       "      <td>Baffin Wind</td>\n",
       "      <td>2014</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Baffin</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>57927_OnshoreWindTurbine_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>150496</td>\n",
       "      <td>1</td>\n",
       "      <td>2197</td>\n",
       "      <td>120.0</td>\n",
       "      <td>45.51</td>\n",
       "      <td>57156</td>\n",
       "      <td>Barton Chapel Wind Farm</td>\n",
       "      <td>2009</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Barton_Chapel_Wind_Farm</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>57156_OnshoreWindTurbine_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>220216</td>\n",
       "      <td>1</td>\n",
       "      <td>3727</td>\n",
       "      <td>196.7</td>\n",
       "      <td>65.47</td>\n",
       "      <td>59972</td>\n",
       "      <td>Bearkat</td>\n",
       "      <td>2018</td>\n",
       "      <td>196.7</td>\n",
       "      <td>Bearkat_I</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>59972_OnshoreWindTurbine_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Texas7k BusNum  Texas7k GenID  Texas7k SubNum  \\\n",
       "0           0             0          190193              1            3131   \n",
       "1           1             1          120493              1            1261   \n",
       "2           2             2          160281              1            2424   \n",
       "3           3             3          150496              1            2197   \n",
       "4           4             4          220216              1            3727   \n",
       "\n",
       "   Texas7k Max MW  Texas7k Min MW  EIA-860 Plant Code  \\\n",
       "0           253.0           34.10               60902   \n",
       "1            99.8           20.75               58000   \n",
       "2           188.0           46.66               57927   \n",
       "3           120.0           45.51               57156   \n",
       "4           196.7           65.47               59972   \n",
       "\n",
       "        EIA-860 Plant Name  EIA-860 Operating Year  \\\n",
       "0             Dermott Wind                    2017   \n",
       "1  Anacacho Wind Farm  LLC                    2012   \n",
       "2              Baffin Wind                    2014   \n",
       "3  Barton Chapel Wind Farm                    2009   \n",
       "4                  Bearkat                    2018   \n",
       "\n",
       "   EIA-860 Nameplate Capacity (MW)           NREL Wind Site  Mapping Status  \\\n",
       "0                            253.0   Amazon_Wind_Farm_Texas               1   \n",
       "1                             99.8       Anacacho_Wind_Farm               1   \n",
       "2                            188.0                   Baffin               1   \n",
       "3                            120.0  Barton_Chapel_Wind_Farm               1   \n",
       "4                            196.7                Bearkat_I               1   \n",
       "\n",
       "   Distribution Factor  NREL Capacity Proportion                     GEN UID  \n",
       "0                  1.0                     330.0  60902_OnshoreWindTurbine_1  \n",
       "1                  1.0                     129.0  58000_OnshoreWindTurbine_1  \n",
       "2                  1.0                     264.0  57927_OnshoreWindTurbine_1  \n",
       "3                  1.0                     157.0  57156_OnshoreWindTurbine_1  \n",
       "4                  1.0                     257.0  59972_OnshoreWindTurbine_1  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to generate the forecasts for the appropriate wind assets \n",
    "wnd_nm = 'WND (Wind)'\n",
    "#get the wind_assets of gen\n",
    "wind_gens = gen[gen['Fuel'] == wnd_nm]\n",
    "wind_mappings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# creates a temporary dataframe for the output\n",
    "temp_output_df_DA = pd.DataFrame({\"Year\": dates.dt.year, \"Month\": dates.dt.month, \"Day\": dates.dt.day, \"Period\": dates.dt.hour})\n",
    "temp_output_df_AC = pd.DataFrame({\"Year\": dates.dt.year, \"Month\": dates.dt.month, \"Day\": dates.dt.day, \"Period\": dates.dt.hour})\n",
    "# creates a dictionary for the number of times the plant code is used\n",
    "# this is necessary because we need to make sure we're pulling the correct distribution factor, nrel capacity, and\n",
    "# texas7k max capacity when scaling in situations where multiple Texas7k generators have the same plant code and\n",
    "# therefore map from the same NREL wind farm\n",
    "plant_codes_num_used = {}\n",
    "gen_codes = np.unique(wind_gens['EIA-860 Plant Code'])\n",
    "times_used = [0]*len(gen_codes)\n",
    "plant_codes_num_used = dict(zip(gen_codes, times_used))\n",
    "\n",
    "# will essentially iterate across the rows of wind_gens\n",
    "# for wind, the assets are essentially mapped 1:1, or close to it. This will not be the case for solar, so our \n",
    "# methodology will change when we get there.\n",
    "for i in np.arange(wind_gens.shape[0]):\n",
    "    # finds the gen uid for the associated row, as well as the plant code\n",
    "    gen_uid = wind_gens.iloc[i]['GEN UID']\n",
    "    gen_code = wind_gens.iloc[i]['EIA-860 Plant Code']\n",
    "    gen_bus = wind_gens.iloc[i]['Bus ID']\n",
    "    # finds the nrel name in wind mappings which agrees with the bus num. this can return lists of length greater than 1\n",
    "    nrel_name = wind_mappings[wind_mappings['Texas7k BusNum'] == gen_bus]['NREL Wind Site']\n",
    "    # finds the index of the correct name in wind_mappings so it can accurately pull the distribution and max capacities\n",
    "    # based on the mappings above, pull the 7k max, NREL capacity, and distribution factor\n",
    "    # note: we won't have to do all of the below for solar because Majid's mappings already took that into account\n",
    "    texas7kmax = wind_mappings[wind_mappings['Texas7k BusNum'] == gen_bus]['Texas7k Max MW']\n",
    "    nrel_capacity = wind_mappings[wind_mappings['Texas7k BusNum'] == gen_bus]['NREL Capacity Proportion']\n",
    "    dist_factor = wind_mappings[wind_mappings['Texas7k BusNum'] == gen_bus]['Distribution Factor']\n",
    "    # will multiply the forecast by the below to scale it for texas 7k\n",
    "    forecast_multiplier = float(dist_factor / nrel_capacity * texas7kmax)\n",
    "    # assign to the output dataframe\n",
    "    tst = wind_forecast_subset[nrel_name] * forecast_multiplier\n",
    "    temp_output_df_DA[gen_uid] = wind_forecast_subset[nrel_name] * forecast_multiplier\n",
    "    temp_output_df_AC[gen_uid] = wind_actual_subset[nrel_name] * forecast_multiplier\n",
    "    plant_codes_num_used[gen_code] += 1\n",
    "temp_output_df_DA.to_csv(\"./TX_Data/timeseries_data_files/WIND/DAY_AHEAD_wind.csv\", index=False)\n",
    "temp_output_df_AC.to_csv(\"./TX_Data/timeseries_data_files/WIND/REAL_TIME_wind.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will handle the load forecasts. This is slightly trickier, as NREL provides 48 hours of forecasts for loads, as opposed to 24. This means that days are double-forecasted, and we have to be careful to make sure we are always pulling from the correct forecast time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Forecast_time', 'Coast', 'East', 'Far_West', 'North', 'North_Central',\n",
      "       'South_Central', 'South', 'West'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "load_forecast_df = pd.read_csv(\"./NREL Stuff/load_day_ahead_forecast_zone_2018.csv\")\n",
    "load_forecasting_horizon = 24\n",
    "hours_in_day = 24\n",
    "days_after_load = 1\n",
    "# delete the first forecast for load\n",
    "load_forecast_df = load_forecast_df.drop_duplicates(subset=['Forecast_time'], keep=\"last\")\n",
    "# dup = load_forecast_df.duplicated(subset = \"Forecast_time\", keep=\"last\")\n",
    "# load_forecast_df = load_forecast_df[~dup.values]\n",
    "# load_forecast_subset = load_forecast_df.iloc[np.maximum(0,(day_of_interest-days_before - 1))*load_forecasting_horizon:np.minimum(365,(day_of_interest+days_after_load))*load_forecasting_horizon,:]\n",
    "# temp = load_forecast_subset.loc[:,'Forecast_time']\n",
    "# dates = pd.to_datetime(temp).dt.tz_localize(\"UTC\")- datetime.timedelta(hours=6) #pull 6 hours for date consistency reasons\n",
    "# wind_forecast_subset.loc[:,'Forecast_time'] = pd.to_datetime(temp.loc[:,:]).\n",
    "load_forecast_subset = load_forecast_df.iloc[forecasts_taper_front:]\n",
    "load_forecast_subset = load_forecast_subset.drop(\"Issue_time\", axis=1)\n",
    "load_forecast_subset = load_forecast_subset.reset_index(drop=True)\n",
    "dates = pd.Series(pd.date_range(start=start_time_local, end=end_time_local, freq='H'))\n",
    "year = dates.dt.year\n",
    "month = dates.dt.month\n",
    "day = dates.dt.day\n",
    "hours = dates.dt.hour#*int(load_forecasting_horizon/hours_in_day))\n",
    "load_output_df_DA = pd.DataFrame({'Year': year, 'Month':month, 'Day':day, 'Period':hours})\n",
    "# this has the first 4 columns set up - what remains is to populate with the appropriate time series which correspond\n",
    "# to the correct assets\n",
    "zones = load_forecast_subset.columns[2:]\n",
    "load_output_df_DA[zones] = load_forecast_subset.loc[:, zones]\n",
    "#print(load_output_df_DA.head(50))\n",
    "load_output_df_DA.to_csv(\"./TX_Data/timeseries_data_files/LOAD/DAY_AHEAD_regional_Load.csv\", index=False)\n",
    "print(zones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do load actuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Time', 'Coast', 'East', 'Far_West', 'North',\n",
      "       'North_Central', 'South_Central', 'South', 'West'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "load_actuals_df = pd.read_csv(\"./NREL Stuff/load_actual_1h_2018.csv\")\n",
    "# load_actuals_horizon = 24\n",
    "# days_after_load_actuals = 0\n",
    "# shift = 6 # shift because of a slight inconsistency; these files go from 6 pm Dec 31 2017 to 6 pm Dec 31 2018 (in local time)\n",
    "# load_actuals_subset = load_actuals_df.iloc[shift + np.maximum(0,(day_of_interest-days_before - 1))*load_actuals_horizon: shift + np.minimum(365,(day_of_interest+days_after_load_actuals))*load_actuals_horizon,:]\n",
    "# temp = load_actuals_subset.loc[:,'Time']\n",
    "# dates = pd.to_datetime(temp).dt.tz_localize(\"UTC\") - datetime.timedelta(hours=6)\n",
    "# once again, the actuals span a longer time than the forecasts, so we taper \n",
    "load_actuals_subset = load_actuals_df.iloc[actuals_taper_front:actuals_taper_back].reset_index(drop=True)\n",
    "year = dates.dt.year\n",
    "month = dates.dt.month\n",
    "day = dates.dt.day\n",
    "hours = dates.dt.hour\n",
    "load_output_df_RT = pd.DataFrame({'Year': year, 'Month':month, 'Day':day, 'Period':hours})\n",
    "# this has the first 4 columns set up - what remains is to populate with the appropriate time series which correspond\n",
    "# to the correct assets\n",
    "zones = load_actuals_subset.columns[2:]\n",
    "print(load_actuals_subset.columns)\n",
    "load_output_df_RT[zones] = load_actuals_subset.loc[:, zones]\n",
    "load_output_df_RT.to_csv(\"./TX_Data/timeseries_data_files/LOAD/REAL_TIME_regional_Load.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start with solar forecast for now.... can turn this into a function that applies to all the asset types later\n",
    "sol_forecast_df = pd.read_csv(\"./NREL Stuff/solar_day_ahead_forecast_site_2018.csv\")\n",
    "sol_actual_df = pd.read_csv(\"./NREL Stuff/solar_actual_1h_site_2018.csv\")\n",
    "sol_forecasting_horizon = 24\n",
    "\n",
    "# ignored for the purposes\n",
    "# we will get some days around the day that we are interested in to populate for this test run\n",
    "days_before = 1\n",
    "days_after = 1\n",
    "day_of_interest = 190 # july 10\n",
    "#sol_forecast_subset = sol_forecast_df.iloc[np.maximum(0,(day_of_interest-days_before - 1))*sol_forecasting_horizon:np.minimum(365,(day_of_interest+days_after))*sol_forecasting_horizon,:]\n",
    "#sol_actual_subset = sol_actual_df.iloc[np.maximum(0,(day_of_interest-days_before-1))*sol_forecasting_horizon:np.minimum(365,(day_of_interest+days_after))*sol_forecasting_horizon,:]\n",
    "\n",
    "sol_forecast_subset = sol_forecast_df # don't need to use the forecast taper here like we did for wind/load\n",
    "\n",
    "sol_actual_subset = sol_actual_df.iloc[actuals_taper_front:actuals_taper_back]\n",
    "sol_actual_subset = sol_actual_subset.reset_index()\n",
    "\n",
    "\n",
    "# getting the year, month, day, and hour in order to mimic the RTS formatting\n",
    "#temp = sol_forecast_subset.loc[:,'Forecast_time']\n",
    "#dates = pd.to_datetime(temp).dt.tz_localize(\"UTC\") - datetime.timedelta(hours=6) #pull 6 hours for date consistency reasons\n",
    "\n",
    "dates = pd.Series(pd.date_range(start=start_time_local, end=end_time_local, freq='H'))\n",
    "\n",
    "year = dates.dt.year\n",
    "month = dates.dt.month\n",
    "day = dates.dt.day\n",
    "hours = dates.dt.hour\n",
    "sol_output_df_DA = pd.DataFrame({'Year': year, 'Month':month, 'Day':day, 'Period':hours})\n",
    "# this has the first 4 columns set up - what remains is to populate with the appropriate time series which correspond\n",
    "# to the correct assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30    1.087\n",
      "Name: dist_factor, dtype: float64\n",
      "21    20.2\n",
      "Name: dist_factor, dtype: float64\n",
      "28    0.7913\n",
      "Name: dist_factor, dtype: float64\n",
      "22    0.7826\n",
      "Name: dist_factor, dtype: float64\n",
      "20    15.75\n",
      "Name: dist_factor, dtype: float64\n",
      "25    0.6522\n",
      "Name: dist_factor, dtype: float64\n",
      "24    0.5152\n",
      "Name: dist_factor, dtype: float64\n",
      "19    0.5043\n",
      "Name: dist_factor, dtype: float64\n",
      "8    3.367\n",
      "Name: dist_factor, dtype: float64\n",
      "33    0.4348\n",
      "Name: dist_factor, dtype: float64\n",
      "32    0.4348\n",
      "Name: dist_factor, dtype: float64\n",
      "31    10.0\n",
      "Name: dist_factor, dtype: float64\n",
      "23    0.4348\n",
      "Name: dist_factor, dtype: float64\n",
      "6    1.3336\n",
      "Name: dist_factor, dtype: float64\n",
      "7    1.3333\n",
      "Name: dist_factor, dtype: float64\n",
      "9    0.983\n",
      "Name: dist_factor, dtype: float64\n",
      "3    0.4423\n",
      "Name: dist_factor, dtype: float64\n",
      "14    2.2727\n",
      "Name: dist_factor, dtype: float64\n",
      "13    0.117\n",
      "Name: dist_factor, dtype: float64\n",
      "12    0.117\n",
      "Name: dist_factor, dtype: float64\n",
      "11    0.117\n",
      "Name: dist_factor, dtype: float64\n",
      "35    0.117\n",
      "Name: dist_factor, dtype: float64\n",
      "5    1.2453\n",
      "Name: dist_factor, dtype: float64\n",
      "4    1.2453\n",
      "Name: dist_factor, dtype: float64\n",
      "10    9.4286\n",
      "Name: dist_factor, dtype: float64\n",
      "34    0.1304\n",
      "Name: dist_factor, dtype: float64\n",
      "2    0.3436\n",
      "Name: dist_factor, dtype: float64\n",
      "1    0.2356\n",
      "Name: dist_factor, dtype: float64\n",
      "0    0.2356\n",
      "Name: dist_factor, dtype: float64\n",
      "29    0.2174\n",
      "Name: dist_factor, dtype: float64\n",
      "27    5.0\n",
      "Name: dist_factor, dtype: float64\n",
      "26    0.2174\n",
      "Name: dist_factor, dtype: float64\n",
      "18    3.02\n",
      "Name: dist_factor, dtype: float64\n",
      "17    1.0\n",
      "Name: dist_factor, dtype: float64\n",
      "16    0.4444\n",
      "Name: dist_factor, dtype: float64\n",
      "15    0.6844\n",
      "Name: dist_factor, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# need to generate the forecasts for the appropriate solar assets \n",
    "sol_nm = 'SUN (Solar)'\n",
    "#get the solar assets of gen\n",
    "sol_gens = gen[gen['Fuel'] == sol_nm]\n",
    "# creates a temporary dataframe for the output\n",
    "temp_output_df_DA = pd.DataFrame({'Year': year, 'Month':month, 'Day':day, 'Period':hours})\n",
    "temp_output_df_AC = pd.DataFrame({'Year': year, 'Month':month, 'Day':day, 'Period':hours})\n",
    "\n",
    "# will essentially iterate across the rows of sol_gens\n",
    "# note that for ERCOT, we have only one generator at each bus, so there is no possibility of a \n",
    "for i in np.arange(sol_gens.shape[0]):\n",
    "    # finds the gen uid for the associated row, as well as the plant code and bus ID\n",
    "    gen_uid = sol_gens.iloc[i]['GEN UID']\n",
    "    bus_id = sol_gens.iloc[i]['Bus ID']\n",
    "    # finds the nrel name in solar mappings which agrees with the bus id.\n",
    "    nrel_name = solar_mappings[solar_mappings['BusNum'] == bus_id]['Min_site']\n",
    "    # gets the appropriate dist factor - note that in this case, since we are using Majid's solar mappings, the dist\n",
    "    # factor alone is sufficient for us to map the solars\n",
    "    nrel_dist_factor = solar_mappings[solar_mappings['BusNum'] == bus_id]['dist_factor']\n",
    "    print(nrel_dist_factor)\n",
    "    # in the case that it is assets that have no NREL map then output zeroes\n",
    "    if (nrel_name.empty):\n",
    "        temp_output_df_DA[gen_uid] = np.zeros(len(sol_forecast_subset))\n",
    "        temp_output_df_AC[gen_uid] = np.zeros(len(sol_actual_subset))\n",
    "        continue\n",
    "    # assign to the output dataframe\n",
    "    temp_output_df_DA[gen_uid] = sol_forecast_subset[nrel_name] * float(nrel_dist_factor)\n",
    "    temp_output_df_AC[gen_uid] = sol_actual_subset[nrel_name] * float(nrel_dist_factor)\n",
    "    plant_codes_num_used[gen_code] += 1\n",
    "temp_output_df_DA.to_csv(\"./TX_Data/timeseries_data_files/PV/DAY_AHEAD_pv.csv\", index=False)\n",
    "temp_output_df_AC.to_csv(\"./TX_Data/timeseries_data_files/PV/REAL_TIME_pv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What remains:\n",
    "* Verify that these are working properly (correct format of output, make sure output reconciles with what it should be, and corresponds to the correct rows)\n",
    "* Verify understanding of time zones - ideally, we should not have any conversion, but in RTS as currently set up, it seems somewhat necessary. We can potentially change this ourselves dow the line\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
